{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This tests the buffer of gestures for movement recognition idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use a deque (which is efficient to append and pop) for this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a buffer class in time later, now we just want to be able to take a sequence of gestures and catch the mov_gesture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bellow we have the sequence of static gestures that generate the gesture for eleven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "eleven = ['one', 'closed_fist', 'one', 'closed_fist']\n",
    "twelve = ['one', 'closed_fist', 'two', 'closed_fist']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume our buffer is the best possible case, i.e., it contains eleven (and only eleven)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating buffer with deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = deque(maxlen=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque(['one', 'closed_fist', 'one', 'closed_fist'], maxlen=4)\n"
     ]
    }
   ],
   "source": [
    "buffer.extend(eleven)\n",
    "print(buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it has a max length of four, adding a new element at right will auto pop at left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque(['closed_fist', 'one', 'closed_fist', 'two'], maxlen=4)\n"
     ]
    }
   ],
   "source": [
    "buffer.append('two')\n",
    "print(buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque(['one', 'closed_fist', 'one', 'closed_fist'], maxlen=4)\n"
     ]
    }
   ],
   "source": [
    "buffer = deque(maxlen=4)\n",
    "buffer.extend(eleven)\n",
    "print(buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exactly what we need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to check if its eleven is to walk trough the buffer and see if attains a check_point == len(eleven)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eleven is in buffer: True\n"
     ]
    }
   ],
   "source": [
    "def seq_in_buff(buffer, gesture_movie):\n",
    "    cp = 0 # Checkpoint starts at zero\n",
    "    len_gesture_movie = len(gesture_movie)\n",
    "    for el in buffer:\n",
    "        if el == gesture_movie[cp]:\n",
    "            cp += 1\n",
    "        if cp == len_gesture_movie:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "print(f'Eleven is in buffer: {seq_in_buff(buffer, eleven)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could make this work with a buffer that contains random other strings, as long as buffer contains gesture_movie in the correct order, it should work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eleven is in buffer: True\n",
      "If we exclude ther first closed_fist block from buffer we get:\n"
     ]
    }
   ],
   "source": [
    "buffer_long_list = [\n",
    "    \"two\",\n",
    "    \"three\",\n",
    "    \"one\", # First\n",
    "    \"three\",\n",
    "    \"two\",\n",
    "    \"one\",\n",
    "    \"closed_fist\", # Second\n",
    "    \"closed_fist\",\n",
    "    \"closed_fist\",\n",
    "    \"closed_fist\",\n",
    "    \"two\",\n",
    "    \"three\",\n",
    "    \"one\", # Third\n",
    "    \"three\",\n",
    "    \"two\",\n",
    "    \"one\",\n",
    "    \"two\",\n",
    "    \"three\",\n",
    "    \"one\", # Last\n",
    "    \"three\",\n",
    "    \"two\",\n",
    "    \"one\",\n",
    "    \"closed_fist\",\n",
    "    \"closed_fist\",\n",
    "    \"closed_fist\",\n",
    "    \"closed_fist\",\n",
    "]\n",
    "buffer_long = deque()\n",
    "buffer_long.extend(buffer_long_list)\n",
    "print(f'Eleven is in buffer: {seq_in_buff(buffer_long, eleven)}')\n",
    "print('If we exclude ther first closed_fist block from buffer we get:')\n",
    "# buffer_long[6:10] = 'one'\n",
    "# print(f'Eleven is in buffer: {seq_in_buff(buffer_long, eleven)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with this approach is, supposedly, that it might be slow. If we assume we are able to optimize everything to make the code recognizer be at 60 fps, we would, for gestures with at most five seconds, have to go through the entire buffer list (with 300 elements) as many times as there are gestures with movement. This can be problematic.\n",
    "\n",
    "One way to deal with this would be to go through the buffer just once, but have one checkpoint for each movement with gesture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seqs_in_buff(buffer, gesture_movies_array):\n",
    "    cp = [0]*len(gesture_movies_array) # Checkpoints start at zero\n",
    "    len_gesture_movies = [len(gesture_movies) for gesture_movies in gesture_movies_array]\n",
    "    for el in buffer:\n",
    "        for i, gesture_movies in enumerate(gesture_movies_array):\n",
    "            if cp[i] < len_gesture_movies[i] and el == gesture_movies[cp[i]]:\n",
    "                cp[i] += 1\n",
    "    identified = [0]*len(gesture_movies_array)\n",
    "    for i in range(len(identified)):\n",
    "        if cp[i] == len_gesture_movies[i]:\n",
    "            identified[i] = 1\n",
    "    return identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eleven and Twelve are in buffer: [1, 1]\n",
      "If we exclude the second two we get:\n",
      "Eleven and Twelve are in buffer: [1, 0]\n"
     ]
    }
   ],
   "source": [
    "buffer = deque(maxlen=6)\n",
    "buffer.extend(['one', 'two', 'closed_fist', 'one', 'two', 'closed_fist'])\n",
    "print(f'Eleven and Twelve are in buffer: {seqs_in_buff(buffer, [eleven, twelve])}')\n",
    "print('If we exclude the second two we get:')\n",
    "buffer[4] = 'one'\n",
    "print(f'Eleven and Twelve are in buffer: {seqs_in_buff(buffer, [eleven, twelve])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eleven and Twelve are in buffer long: [1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(f'Eleven and Twelve are in buffer long: {seqs_in_buff(buffer_long, [eleven, twelve])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this more efficient? Let's add a thousand elements in front of buffer and see how long it takes to run seq_in_buff in eleven and twelve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"collections.deque\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m elements \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m300\u001b[39m)\n\u001b[1;32m      4\u001b[0m long_garbage \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgarbage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m (elements\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(buffer_long))\n\u001b[0;32m----> 5\u001b[0m long_buffer \u001b[38;5;241m=\u001b[39m \u001b[43mlong_garbage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbuffer_long\u001b[49m\u001b[38;5;66;03m# Thousand elements buffer\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"collections.deque\") to list"
     ]
    }
   ],
   "source": [
    "n_movements = 1000\n",
    "movs = [eleven, twelve] * int(n_movements/2)\n",
    "elements = int(300)\n",
    "long_garbage = ['garbage'] * (elements-len(buffer_long))\n",
    "long_buffer = long_garbage + buffer_long# Thousand elements buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "# for mov in movs:\n",
    "    # seq_in_buff(long_buffer, mov)\n",
    "for i in range(10):\n",
    "    [seq_in_buff(long_buffer, mov) for mov in movs]\n",
    "end_time = time.time()\n",
    "print(f'Time elapsed: {(end_time - start_time)/10}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time1 = time.time()\n",
    "for i in range(10):\n",
    "    seqs_in_buff(long_buffer, movs)\n",
    "end_time1 = time.time()\n",
    "print(f'Time elapsed: {(end_time1 - start_time1)/10}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently its faster to just run seq_in_buff for all movs instead of trying to do all togheter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way would be to make the checkpoints in the same way they are implemented in the class right now and just update them, would this be faster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_cps(incoming_frame, cps, gesture_movies_array):\n",
    "    for i, gesture_movies in enumerate(gesture_movies_array):\n",
    "        if cps[i] < len(gesture_movies) and incoming_frame == gesture_movies[cps[i]]:\n",
    "            cps[i] += 1\n",
    "    return cps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cps = [0]*len(movs)\n",
    "start_time2 = time.time()\n",
    "for i in range(10):\n",
    "    [update_cps(el, cps, movs) for el in long_buffer]\n",
    "end_time2 = time.time()\n",
    "print(f'Time elapsed: {(end_time2 - start_time2)/10}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is better but not best, the difference here is that if we want to add another frame, the check is much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_buffer_p1 = long_buffer + ['one']\n",
    "start_time3 = time.time()\n",
    "for i in range(1000):\n",
    "    update_cps(['one'], cps, movs)\n",
    "end_time3 = time.time()\n",
    "print(f'Time elapsed: {(end_time3 - start_time3)/1000}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is very good, $143 \\mu s$. There are as many checks as there are movements, and no more, regardless of how long the buffer is!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only difference in the class would be to make check point be a list!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note also that this doesn't lock any gesture with movement recognition!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing that could be done is to keep, along with cp, the error for the measurement of each static figure. If there are more than one cp identified at the end of 5 seconds, we can then choose the one that has the smaller error. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
